{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.mlab as ml\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import matplotlib.ticker as plticker\n",
    "\n",
    "def stdfigsize(scale=1, nx=1, ny=1, ratio=1.3):\n",
    "    \"\"\"\n",
    "    Returns a tuple to be used as figure size.\n",
    "    -------\n",
    "    returns (7*ratio*scale*nx, 7.*scale*ny)\n",
    "    By default: ratio=1.3\n",
    "    If ratio<0 them ratio = golden ratio\n",
    "    \"\"\"\n",
    "    if ratio < 0:\n",
    "        ratio = 1.61803398875\n",
    "    return((7*ratio*scale*nx, 7*scale*ny))\n",
    "\n",
    "def stdrcparams(usetex=False):\n",
    "    \"\"\"\n",
    "    Set several mpl.rcParams and sns.set_style for my taste.\n",
    "    ----\n",
    "    usetex = True\n",
    "    ----\n",
    "    \"\"\"\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_style({\"xtick.direction\": \"in\",\n",
    "                 \"ytick.direction\": \"in\"})\n",
    "    rcparams = {'text.usetex': usetex,\n",
    "              'font.family': 'sans-serif',\n",
    "              'font.sans-serif': ['Helvetica'],\n",
    "             # 'text.latex.unicode': True,\n",
    "              'text.latex.preamble': [r\"\\usepackage[T1]{fontenc}\",\n",
    "                                      r\"\\usepackage{lmodern}\",\n",
    "                                      r\"\\usepackage{amsmath}\",\n",
    "                                      r\"\\usepackage{mathptmx}\"\n",
    "                                      ],\n",
    "              'axes.labelsize': 30,\n",
    "              'axes.titlesize': 30,\n",
    "              'ytick.right': 'on',\n",
    "              'xtick.top': 'on',\n",
    "              'xtick.labelsize': '25',\n",
    "              'ytick.labelsize': '25',\n",
    "              'axes.linewidth': 1.8,\n",
    "              'xtick.major.width': 1.8,\n",
    "              'xtick.minor.width': 1.8,\n",
    "              'xtick.major.size': 14,\n",
    "              'xtick.minor.size': 7,\n",
    "              'xtick.major.pad': 10,\n",
    "              'xtick.minor.pad': 10,\n",
    "              'ytick.major.width': 1.8,\n",
    "              'ytick.minor.width': 1.8,\n",
    "              'ytick.major.size': 14,\n",
    "              'ytick.minor.size': 7,\n",
    "              'ytick.major.pad': 10,\n",
    "              'ytick.minor.pad': 10,\n",
    "              'axes.labelpad': 15,\n",
    "              'axes.titlepad': 15,\n",
    "              \"xtick.direction\": \"in\",\n",
    "              \"ytick.direction\": \"in\",\n",
    "              'legend.fontsize': 20}\n",
    "    mpl.rcParams.update(rcparams) \n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 5\n",
    "mpl.rcParams['lines.color'] = '#3690c0'\n",
    "\n",
    "stdrcparams(usetex=True)\n",
    "figsize=stdfigsize(ratio=-1)\n",
    "xs,ys=figsize\n",
    "\n",
    "def custom_frame(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.tick_params(axis='x',length=10,direction='out')\n",
    "    ax.tick_params(axis='x',which='minor',direction='out')\n",
    "    ax.tick_params(axis='y',length=10,direction='out')\n",
    "    ax.tick_params(axis='y',which='minor',direction='out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "import random\n",
    "\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air = pd.read_pickle('../data/networks/US_air_1990_2018.pkl')\n",
    "nodes = set(df_air.source.unique())|set(df_air.target.unique())\n",
    "df_air = df_air[df_air.source != df_air.target]\n",
    "year = list(df_air.index.get_level_values(0).unique())\n",
    "month = list(df_air.index.get_level_values(1).unique())\n",
    "graphs_air = []\n",
    "date_air = []\n",
    "for y in year:\n",
    "    for m in month:\n",
    "#        if y != 2018 or m != 12:\n",
    "        df = df_air.loc[y,m]\n",
    "        date_air.append(date(y,m,1))\n",
    "        G = nx.from_pandas_edgelist(df_air.loc[y,m], edge_attr=True)\n",
    "        G.add_nodes_from(nodes)\n",
    "        graphs_air.append(G)\n",
    "        \n",
    "\n",
    "n = date_air.index(date(2004,1,1))\n",
    "graphs_air = graphs_air[n:]\n",
    "date_air =  date_air[n:]\n",
    "\n",
    "del df_air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_datasets(data):\n",
    "    allcities=pd.read_csv(\"../data/buses_list_of_cities.csv\",index_col=0,names=[\"CityUF\"],encoding=\"utf-8\")\n",
    "    allcities.head()    \n",
    "    allcities[\"CityUF\"]=allcities[\"CityUF\"].str.upper()\n",
    "    allcities[\"CityUF\"]=allcities[\"CityUF\"].str.strip()\n",
    "    allcities[\"CityUF\"]=allcities[\"CityUF\"].str.replace(\" , \",\", \")\n",
    "    allcities[\"CityUF\"]=allcities[\"CityUF\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    setallcities=set(list(allcities.CityUF.astype(str)))    \n",
    "    data=data[data['ORIGEM'].isin(list(setallcities))]\n",
    "    data=data[data['DESTINO'].isin(list(setallcities))]    \n",
    "    return data\n",
    "\n",
    "def bus_network(year=2010,month=12):\n",
    "    data=pd.read_csv(\"../data/cleaned_buses_data/{}.csv\".format(year),index_col=None)\n",
    "    if month is not False:\n",
    "        data=data[data.MES==month]\n",
    "    data=data[data.NUMEROLUGAROFERTADOIDA>0]\n",
    "    data=match_datasets(data)\n",
    "    data=data[[\"ORIGEM\",\"DESTINO\"]]\n",
    "    data=data.groupby(data.columns.tolist()).size().reset_index().rename(columns={0:'weight'})\n",
    "    data=data.rename(columns={'ORIGEM':'source','DESTINO':'target','NUMEROLUGAROFERTADOIDA':'weight'})\n",
    "    return data\n",
    "\n",
    "df_bus = pd.read_pickle('../data/networks/bus_2005_2014.pkl')\n",
    "df_bus = df_bus[df_bus.source != df_bus.target]\n",
    "year = list(df_bus.index.get_level_values(0).unique())\n",
    "month = list(df_bus.index.get_level_values(1).unique())\n",
    "graphs_bus = []\n",
    "date_bus = []\n",
    "for y in year:\n",
    "    for m in month:\n",
    "#        if y != 2018 or m != 12:\n",
    "        df = bus_network(y,m)\n",
    "        date_bus.append(date(y,m,1))\n",
    "        G = nx.from_pandas_edgelist(df, edge_attr=True)\n",
    "        graphs_bus.append(G)\n",
    "del df_bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_air = pd.read_pickle('../results/us_air_data_binary_adding.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bus = pd.read_pickle('../results/brazil_bus_data_binary_adding.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split edges into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_slice(data,f_train_e=0.7,seed=30):\n",
    "    df = data\n",
    "    edges = list(df.Edge.unique())\n",
    "    random.seed(seed)\n",
    "    edge_train = random.sample(edges,int(f_train_e*len(edges)))\n",
    "    edge_test = [e for e in edges if e not in edge_train]\n",
    "    df_se = df.loc[df['Edge'].isin(edge_train)].drop(columns = ['Edge','Time'])\n",
    "    df_de = df.loc[df['Edge'].isin(edge_test)].drop(columns = ['Edge','Time'])\n",
    "    return(df_se,df_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_se,air_de = get_edge_slice(df_air)\n",
    "bus_se,bus_de = get_edge_slice(df_bus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_path(G,nodelist,epsilon = 0.01):\n",
    "    A = nx.adjacency_matrix(G,weight=None).todense()\n",
    "    return(A**2+epsilon*A**3)\n",
    "\n",
    "def my_devide(a,b):\n",
    "    if a!=0 and b!=0:\n",
    "        return a/b\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_vector(G,H,edges):\n",
    "    X,y = [],[]\n",
    "    Ki = G.degree()\n",
    "    nodelist = list(G.nodes())\n",
    "    LPI = local_path(G,nodelist)\n",
    "    for e in edges:\n",
    "        u,v = e\n",
    "        union_size = len(set(G[u])|set(G[v]))\n",
    "        x = []\n",
    "        uv_intersection = list(nx.common_neighbors(G,u,v))\n",
    "        x.append(len(uv_intersection))\n",
    "        x.append(my_devide(len(uv_intersection),np.sqrt(Ki[u]*Ki[v])))\n",
    "        x.append(my_devide(len(uv_intersection),union_size))\n",
    "        x.append(my_devide(2*len(uv_intersection),(Ki[u]+Ki[v])))\n",
    "        x.append(my_devide(len(uv_intersection),min(Ki[u],Ki[v])))\n",
    "        x.append(my_devide(len(uv_intersection),max(Ki[u],Ki[v])))\n",
    "        x.append(my_devide(len(uv_intersection),(Ki[u]*Ki[v])))\n",
    "        x.append(Ki[u]*Ki[v])\n",
    "        if len(uv_intersection) == 0:\n",
    "            x.append(0)\n",
    "            x.append(0)\n",
    "        else:    \n",
    "            x.append(sum([1/math.log(Ki[z]) for z in uv_intersection]))\n",
    "            x.append(sum(1/Ki[z] for z in uv_intersection))\n",
    "        x.append(LPI[nodelist.index(u),nodelist.index(v)])\n",
    "        y.append(int(H.has_edge(u,v)))\n",
    "        X.append(x)\n",
    "    return(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test(graphs,dates,year_test,N=10000):\n",
    "    i = dates.index(year_test)\n",
    "    G  = graphs[i]\n",
    "    H = graphs[i+1]\n",
    "    nodes = list(G.nodes())\n",
    "    edges = random.choices(list(itertools.combinations(nodes,2)),k=N)\n",
    "    edges = list(set(edges).difference(set(G.edges())))\n",
    "    X_test,y_test = get_vector(G,H,edges)  \n",
    "    return(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(df_se,df_de,graphs,dates,year_train=date(2004,1,1),year_test = date(2004,2,1),N=5,N_smaple=10000):\n",
    "    df_se = df_se.drop(columns= ['Edge'])\n",
    "    df_de = df_de.drop(columns= ['Edge'])\n",
    "    X_train,y_train = df_se[df_se.Year == year_train].drop(columns=['Year','Label']).values,\\\n",
    "                    df_se[df_se.Year == year_train]['Label'].values\n",
    " \n",
    "    clf = XGBClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    y_train_shuffled = np.copy(y_train)\n",
    "    np.random.shuffle(y_train_shuffled)\n",
    "    null = XGBClassifier()\n",
    "    null.fit(X_train,y_train_shuffled)\n",
    "    cms,cms_null = [],[]\n",
    "    for i in range(N):    \n",
    "        X_test,y_test = get_test(graphs,dates,year_test,N=N_smaple)\n",
    "        y_pred = clf.predict(X_test) \n",
    "        y_pred_null = null.predict(X_test)\n",
    "        cm = confusion_matrix(y_test,y_pred,labels = [1,0])\n",
    "        cm_null = confusion_matrix(y_test,y_pred_null,labels = [1,0])\n",
    "        cms.append(cm.astype('float') / cm.sum(axis = 1)[:,None])\n",
    "        cms_null.append(cm_null.astype('float') / cm_null.sum(axis = 1)[:,None])   \n",
    "    return(np.average(cms,axis=0),np.average(cms_null,axis=0))\n",
    "\n",
    "def pure_plot_confusion_matrix(cm, ax = None):  \n",
    "    classes = ['NtoP','NtoN']\n",
    "    #classes = [0,1]\n",
    "    sns.heatmap(cm, square = True, annot= True, cbar = False, cmap=plt.cm.Blues,ax = ax,annot_kws={\"fontsize\":25})\n",
    "    ax.set_xlim(0,2)\n",
    "    ax.tick_params( bottom=False, right=False,left=False, labeltop=False, labelbottom=True)   \n",
    "    ax.set(xticks = np.arange(cm.shape[1])+0.5,\n",
    "           yticks = np.arange(cm.shape[0])+0.25,\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           ylabel = 'True label',\n",
    "           xlabel = 'Predicted label') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms_air,cms_null_air = get_confusion_matrix(air_se,air_de,graphs_air,date_air,year_train=date(2004,1,1),year_test = date(2004,1,1),N=10,N_smaple=500000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
