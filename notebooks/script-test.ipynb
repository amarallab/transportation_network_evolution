{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../scripts1/get_graphs_decay.py\n",
    "import pickle\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "def get_edge_slice(data,f_train_e=0.7,seed=30):\n",
    "    df = data\n",
    "    edges = list(df.Edge.unique())\n",
    "    random.seed(seed)\n",
    "    edge_train = random.sample(edges,int(f_train_e*len(edges)))\n",
    "    edge_test = [e for e in edges if e not in edge_train]\n",
    "    df_se = df.loc[df['Edge'].isin(edge_train)].drop(columns = ['Edge','Time'])\n",
    "    df_de = df.loc[df['Edge'].isin(edge_test)].drop(columns = ['Edge','Time'])\n",
    "    return(df_se,df_de)\n",
    "\n",
    "def get_time_slice(data,time_start,time_end,droptime=True):\n",
    "    if droptime:\n",
    "        return(data[data.Year >= time_start][data.Year <= time_end].drop(columns = ['Year']))\n",
    "    else:\n",
    "        return(data[data.Year >= time_start][data.Year <= time_end])\n",
    "\n",
    "def df_to_XY(df):\n",
    "    if 'Year' in df.columns:\n",
    "        df = df.drop(columns = ['Year'])\n",
    "        if \"Edge\" in df.columns:\n",
    "            df = df.drop(columns = ['Edge'])\n",
    "    X,y = df.loc[:, df.columns != 'Label'].to_numpy(),\\\n",
    "    df.loc[:, df.columns == 'Label'].to_numpy()\n",
    "    return(X,y)\n",
    "\n",
    "\n",
    "def local_path(G,nodelist,epsilon = 0.01):\n",
    "    A = nx.adjacency_matrix(G,weight=None).todense()\n",
    "    return(A**2+epsilon*A**3)\n",
    "\n",
    "def my_devide(a,b):\n",
    "    if a!=0 and b!=0:\n",
    "        return a/b\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_vector(G,edges):\n",
    "    X,y = [],[]\n",
    "    Ki = G.degree()\n",
    "    nodelist = list(G.nodes())\n",
    "    LPI = local_path(G,nodelist)\n",
    "    NBs = dict([(u,set(G[u])) for u in G.nodes()])\n",
    "    for e in edges:\n",
    "        u,v = e\n",
    "        union_size = len(NBs[u]|NBs[v])\n",
    "        x = []\n",
    "        uv_intersection = list(nx.common_neighbors(G,u,v))\n",
    "        x.append(len(uv_intersection))\n",
    "        x.append(my_devide(len(uv_intersection),np.sqrt(Ki[u]*Ki[v])))\n",
    "        x.append(my_devide(len(uv_intersection),union_size))\n",
    "        x.append(my_devide(2*len(uv_intersection),(Ki[u]+Ki[v])))\n",
    "        x.append(my_devide(len(uv_intersection),min(Ki[u],Ki[v])))\n",
    "        x.append(my_devide(len(uv_intersection),max(Ki[u],Ki[v])))\n",
    "        x.append(my_devide(len(uv_intersection),(Ki[u]*Ki[v])))\n",
    "        x.append(Ki[u]*Ki[v])\n",
    "        if len(uv_intersection) == 0:\n",
    "            x.append(0)\n",
    "            x.append(0)\n",
    "        else:\n",
    "            x.append(sum([1/math.log(Ki[z]) for z in uv_intersection]))\n",
    "            x.append(sum(1/Ki[z] for z in uv_intersection))\n",
    "        x.append(LPI[nodelist.index(u),nodelist.index(v)])\n",
    "        X.append(x)\n",
    "    return(X,y)\n",
    "\n",
    "\n",
    "def new_get_test(G,N=10000):\n",
    "    nodes = list(G.nodes())\n",
    "    edges = random.choices(list(itertools.combinations(nodes,2)),k=N)\n",
    "    edges = list(set(edges).difference(set(G.edges())))\n",
    "    X_test,y_test = get_vector(G,edges)\n",
    "    return(edges,X_test,y_test)\n",
    "\n",
    "def new_get_test_null(G,N=10000):\n",
    "    nodes = list(G.nodes())\n",
    "    edges = random.choices(list(itertools.combinations(nodes,2)),k=N)\n",
    "    edges = list(set(edges).difference(set(G.edges())))\n",
    "#    X_test,y_test = get_vector(G,edges)  \n",
    "    return(edges)\n",
    "\n",
    "df_removal = pd.read_pickle('../results/us_air_data_binary_removal.pkl').replace([np.inf, -np.inf], np.nan).dropna(how='all')\n",
    "df_removal = df_removal[df_removal.year>=date(2004,1,1)]\n",
    "rename_dict = {}\n",
    "for column in df_removal.columns:\n",
    "    if '_index' in column:\n",
    "        column_v = column.replace('_index','',1)\n",
    "    else:\n",
    "        column_v =  column\n",
    "    rename_dict[column]=column_v.replace('_',' ',3).title()\n",
    "\n",
    "rename_again = {'Common Neighbor' : 'CN', 'Salton':'SA' , 'Jaccard':'JA', 'Sorensen':'SO', 'Hub Promoted':'HPI',\n",
    "       'Hub Depressed':'HDI', 'Leicht Holme Newman':'LHNI', 'Preferential Attachment':'PA',\n",
    "       'Adamic Adar':'AA', 'Resource Allocation':'RA', 'Local Path':'LP'}\n",
    "\n",
    "df_removal = df_removal.rename(columns=rename_dict).rename(columns={'Prederential Attachment':'Preferential Attachment'})\n",
    "\n",
    "columns=['Common Neighbor', 'Salton', 'Jaccard', 'Sorensen', 'Hub Promoted',\n",
    "       'Hub Depressed', 'Leicht Holme Newman', 'Preferential Attachment',\n",
    "       'Adamic Adar', 'Resource Allocation', 'Local Path',\n",
    "        'Year','Edge','Time','Label']\n",
    "\n",
    "df_removal =  df_removal[columns]#.rename(columns=rename_again)\n",
    "\n",
    "df_add = pd.read_pickle('../results/us_air_data_binary_adding.pkl')\n",
    "df_add = df_add[df_add.Year>=date(2004,1,1)]\n",
    "\n",
    "df_air = pd.read_pickle('../data/networks/US_air_1990_2018.pkl')\n",
    "nodes = set(df_air.source.unique())|set(df_air.target.unique())\n",
    "df_air = df_air[df_air.source != df_air.target]\n",
    "year = list(df_air.index.get_level_values(0).unique())\n",
    "month = list(df_air.index.get_level_values(1).unique())\n",
    "graphs_air = []\n",
    "date_air = []\n",
    "for y in year:\n",
    "    for m in month:\n",
    "#        if y != 2018 or m != 12:\n",
    "        df = df_air.loc[y,m]\n",
    "        date_air.append(date(y,m,1))\n",
    "        G = nx.from_pandas_edgelist(df_air.loc[y,m], edge_attr=True)\n",
    "        G.add_nodes_from(nodes)\n",
    "        graphs_air.append(G)\n",
    "\n",
    "\n",
    "n = date_air.index(date(2004,1,1))\n",
    "graphs_air = graphs_air[n:]\n",
    "date_air =  date_air[n:]\n",
    "\n",
    "del df_air\n",
    "\n",
    "removal_model = pickle.load(open(\"../results/binary_removal_model.pickle.dat\", \"rb\"))\n",
    "add_model = pickle.load(open(\"../results/binary_adding_model.pickle.dat\", \"rb\"))\n",
    "\n",
    "number_add = df_add[[\"Year\",'Label']].groupby(by=\"Year\").sum()\n",
    "number_remove = df_removal[[\"Year\",'Label']].groupby(by=\"Year\").sum()\n",
    "\n",
    "def get_graphs(remove_rate=1.02,add_rate=1.0):\n",
    "    N_remove = int(number_add.mean().Label*remove_rate)\n",
    "    N_add = int(number_add.mean().Label*add_rate)\n",
    "    graphs_new1 = []\n",
    "    graphs_null1 = []\n",
    "    G = graphs_air[0].copy()\n",
    "    G_null = graphs_air[0].copy()\n",
    "#    for n in range(2)\n",
    "    for n in range(len(graphs_air)-1):\n",
    "        year_train = date_air[n]\n",
    "#        N_remove = number_remove.loc[year_train,'Label']\n",
    "#        N_add = number_add.loc[year_train,'Label']  \n",
    "        \n",
    "        edges = new_get_test_null(G_null)\n",
    "        remove_edges_null = random.choices(edges,k=N_remove)\n",
    "        add_edges_null = random.choices(edges,k=N_add)\n",
    "        G_null.remove_edges_from(remove_edges_null)\n",
    "        G_null.add_edges_from(add_edges_null)\n",
    "        graphs_null1.append(G_null.copy())\n",
    "        \n",
    "        edges = list(G.edges())\n",
    "        X,_ = get_vector(G,edges)\n",
    "        pred_prob = removal_model.predict_proba(X).T[1]\n",
    "        removal = zip(edges,pred_prob)\n",
    "        removal = sorted(removal, key = lambda x: x[1])[0:N_remove]\n",
    "        remove_edges = [i for i,_ in removal]    \n",
    "        edges,X_test,y_test = new_get_test(G)\n",
    "        y_pred = add_model.predict_proba(X_test).T[1]\n",
    "        add_edges = [i for _,i in sorted(zip(y_pred,edges),reverse=True)][0:N_add]\n",
    "        G.remove_edges_from(remove_edges)\n",
    "        G.add_edges_from(add_edges)\n",
    "        graphs_new1.append(G.copy())\n",
    "        print(f'{n} of {len(graphs_air)-2} in loop {m}')\n",
    "    return(graphs_new1,graphs_null1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 178 in loop 12\n",
      "1 of 178 in loop 12\n",
      "2 of 178 in loop 12\n",
      "3 of 178 in loop 12\n",
      "4 of 178 in loop 12\n",
      "5 of 178 in loop 12\n",
      "6 of 178 in loop 12\n",
      "7 of 178 in loop 12\n",
      "8 of 178 in loop 12\n",
      "9 of 178 in loop 12\n",
      "10 of 178 in loop 12\n",
      "11 of 178 in loop 12\n",
      "12 of 178 in loop 12\n",
      "13 of 178 in loop 12\n",
      "14 of 178 in loop 12\n",
      "15 of 178 in loop 12\n",
      "16 of 178 in loop 12\n",
      "17 of 178 in loop 12\n",
      "18 of 178 in loop 12\n",
      "19 of 178 in loop 12\n",
      "20 of 178 in loop 12\n",
      "21 of 178 in loop 12\n",
      "22 of 178 in loop 12\n",
      "23 of 178 in loop 12\n",
      "24 of 178 in loop 12\n",
      "25 of 178 in loop 12\n",
      "26 of 178 in loop 12\n",
      "27 of 178 in loop 12\n",
      "28 of 178 in loop 12\n",
      "29 of 178 in loop 12\n",
      "30 of 178 in loop 12\n",
      "31 of 178 in loop 12\n",
      "32 of 178 in loop 12\n",
      "33 of 178 in loop 12\n",
      "34 of 178 in loop 12\n",
      "35 of 178 in loop 12\n",
      "36 of 178 in loop 12\n",
      "37 of 178 in loop 12\n",
      "38 of 178 in loop 12\n",
      "39 of 178 in loop 12\n",
      "40 of 178 in loop 12\n",
      "41 of 178 in loop 12\n",
      "42 of 178 in loop 12\n",
      "43 of 178 in loop 12\n",
      "44 of 178 in loop 12\n",
      "45 of 178 in loop 12\n",
      "46 of 178 in loop 12\n",
      "47 of 178 in loop 12\n",
      "48 of 178 in loop 12\n",
      "49 of 178 in loop 12\n",
      "50 of 178 in loop 12\n",
      "51 of 178 in loop 12\n",
      "52 of 178 in loop 12\n",
      "53 of 178 in loop 12\n",
      "54 of 178 in loop 12\n",
      "55 of 178 in loop 12\n",
      "56 of 178 in loop 12\n",
      "57 of 178 in loop 12\n",
      "58 of 178 in loop 12\n",
      "59 of 178 in loop 12\n",
      "60 of 178 in loop 12\n",
      "61 of 178 in loop 12\n",
      "62 of 178 in loop 12\n",
      "63 of 178 in loop 12\n",
      "64 of 178 in loop 12\n",
      "65 of 178 in loop 12\n",
      "66 of 178 in loop 12\n",
      "67 of 178 in loop 12\n",
      "68 of 178 in loop 12\n",
      "69 of 178 in loop 12\n",
      "70 of 178 in loop 12\n",
      "71 of 178 in loop 12\n",
      "72 of 178 in loop 12\n",
      "73 of 178 in loop 12\n",
      "74 of 178 in loop 12\n",
      "75 of 178 in loop 12\n",
      "76 of 178 in loop 12\n",
      "77 of 178 in loop 12\n",
      "78 of 178 in loop 12\n",
      "79 of 178 in loop 12\n",
      "80 of 178 in loop 12\n",
      "81 of 178 in loop 12\n",
      "82 of 178 in loop 12\n",
      "83 of 178 in loop 12\n",
      "84 of 178 in loop 12\n",
      "85 of 178 in loop 12\n",
      "86 of 178 in loop 12\n",
      "87 of 178 in loop 12\n",
      "88 of 178 in loop 12\n",
      "89 of 178 in loop 12\n",
      "90 of 178 in loop 12\n",
      "91 of 178 in loop 12\n",
      "92 of 178 in loop 12\n",
      "93 of 178 in loop 12\n",
      "94 of 178 in loop 12\n",
      "95 of 178 in loop 12\n",
      "96 of 178 in loop 12\n",
      "97 of 178 in loop 12\n",
      "98 of 178 in loop 12\n",
      "99 of 178 in loop 12\n",
      "100 of 178 in loop 12\n",
      "101 of 178 in loop 12\n",
      "102 of 178 in loop 12\n",
      "103 of 178 in loop 12\n",
      "104 of 178 in loop 12\n",
      "105 of 178 in loop 12\n",
      "106 of 178 in loop 12\n",
      "107 of 178 in loop 12\n",
      "108 of 178 in loop 12\n",
      "109 of 178 in loop 12\n",
      "110 of 178 in loop 12\n",
      "111 of 178 in loop 12\n",
      "112 of 178 in loop 12\n",
      "113 of 178 in loop 12\n",
      "114 of 178 in loop 12\n",
      "115 of 178 in loop 12\n",
      "116 of 178 in loop 12\n",
      "117 of 178 in loop 12\n",
      "118 of 178 in loop 12\n",
      "119 of 178 in loop 12\n"
     ]
    }
   ],
   "source": [
    "graphs_new1,graphs_null1 = get_graphs(1.03,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
